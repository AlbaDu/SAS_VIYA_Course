{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgYJ2E9KiO88CAp+g546PB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbaDu/SAS_VIYA_Course/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fnihKkpD5sg"
      },
      "source": [
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dih_LRASEGRk"
      },
      "source": [
        "n = 10\n",
        "street_names = ['abbey', 'baker', 'canal', 'donner', 'elm']\n",
        "street_types = ['rd', 'st', 'ln', 'pass', 'ave']\n",
        "random.seed(42) \n",
        "rand_zips = [random.randint(65000,65999) for i in range(5)]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9y1PW_fER2g"
      },
      "source": [
        "#Function to randomly create one typo in a string w/ a probability\n",
        "def create_typo(s, prob=0.75):\n",
        "  if random.uniform(0,1) < prob:\n",
        "    rand_ind = random.choice(range(len(s)))\n",
        "    s_list = list(s)\n",
        "    s_list[rand_ind]=random.choice(string.ascii_lowercase)\n",
        "    s = ''.join(s_list)\n",
        "  return(s)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1O36tBTEf8Y"
      },
      "source": [
        "# Generate the reference dataset\n",
        "numbers = [random.randint(1, 9999) for i in range(n)]\n",
        "streets = [random.choice(street_names) for i in range(n)]\n",
        "street_suffs = [random.choice(street_types) for i in range(n)]\n",
        "zips = [random.choice(rand_zips) for i in range(n)]\n",
        "full_streets = [str(x) + ' ' + y + ' ' + z for x,y,z in zip(numbers, streets, street_suffs)]\n",
        "reference_data = [list(x) for x in zip(full_streets,zips)]\n",
        "\n",
        "# Generate test dataset with some typos\n",
        "typo_streets = [create_typo(x) for x in streets]\n",
        "typo_full_streets = [str(x) + ' ' + y + ' ' + z for x,y,z in zip(numbers, typo_streets, street_suffs)]\n",
        "test_data = [list(x) for x in zip(typo_full_streets,zips)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YexIqOmEpnc",
        "outputId": "ace2466d-035c-45a9-d959-5230a4613bbc"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Create graph\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "# Placeholders\n",
        "test_address = tf.sparse_placeholder( dtype=tf.string)\n",
        "test_zip = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
        "ref_address = tf.sparse_placeholder(dtype=tf.string)\n",
        "ref_zip = tf.placeholder(shape=[None, n], dtype=tf.float32)\n",
        "\n",
        "# Declare Zip code distance for a test zip and reference set\n",
        "zip_dist = tf.square(tf.subtract(ref_zip, test_zip))\n",
        "\n",
        "# Declare Edit distance for address\n",
        "address_dist = tf.edit_distance(test_address, ref_address, normalize=True)\n",
        "\n",
        "# Create similarity scores\n",
        "zip_max = tf.gather(tf.squeeze(zip_dist), tf.argmax(zip_dist, 1))\n",
        "zip_min = tf.gather(tf.squeeze(zip_dist), tf.argmin(zip_dist, 1))\n",
        "zip_sim = tf.div(tf.subtract(zip_max, zip_dist), tf.subtract(zip_max, zip_min))\n",
        "address_sim = tf.subtract(1., address_dist)\n",
        "\n",
        "# Combine distance functions\n",
        "address_weight = 0.5\n",
        "zip_weight = 1. - address_weight\n",
        "weighted_sim = tf.add(tf.transpose(tf.multiply(address_weight, address_sim)), tf.multiply(zip_weight, zip_sim))\n",
        "\n",
        "# Predict: Get max similarity entry\n",
        "top_match_index = tf.argmax(weighted_sim, 1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From <ipython-input-10-733642565f3a>:22: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RItLfVwyGQvF"
      },
      "source": [
        "# Function to Create a character-sparse tensor from strings\n",
        "def sparse_from_word_vec(word_vec):\n",
        "  num_words = len(word_vec)\n",
        "  indices = [[xi, 0, yi] for xi,x in enumerate(word_vec) for yi,y in enumerate(x)]\n",
        "  chars = list(''.join(word_vec))\n",
        "  return(tf.SparseTensorValue(indices, chars, [num_words,1,1]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppSEt0sG-BR",
        "outputId": "36924e1d-8c1b-49bc-f45f-4267ee1b6869"
      },
      "source": [
        "# Loop through test indices\n",
        "reference_addresses = [x[0] for x in reference_data]\n",
        "reference_zips = np.array([[x[1] for x in reference_data]])\n",
        "\n",
        "# Create sparse address reference set\n",
        "sparse_ref_set = sparse_from_word_vec(reference_addresses)\n",
        "for i in range(n):\n",
        "  test_address_entry = test_data[i][0]\n",
        "  test_zip_entry = [[test_data[i][1]]]\n",
        "  \n",
        "# Create sparse address vectors\n",
        "test_address_repeated = [test_address_entry] * n\n",
        "sparse_test_set = sparse_from_word_vec(test_address_repeated)\n",
        "feeddict={test_address: sparse_test_set,\n",
        "test_zip: test_zip_entry,\n",
        "ref_address: sparse_ref_set,\n",
        "ref_zip: reference_zips}\n",
        "best_match = sess.run(top_match_index, feed_dict=feeddict)\n",
        "best_street = reference_addresses[best_match[0]]\n",
        "[best_zip] = reference_zips[0][best_match]\n",
        "[[test_zip_]] = test_zip_entry\n",
        "print('Address: ' + str(test_address_entry) + ', ' + str(test_zip_))\n",
        "print('Match : ' + str(best_street) + ', ' + str(best_zip))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Address: 489 donner st, 65025\n",
            "Match : 489 donner st, 65025\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}